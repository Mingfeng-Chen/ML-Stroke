{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 299)\n",
      "(400000, 1)\n",
      "(33119, 299)\n",
      "(400000, 1594)\n",
      "(33119, 1542)\n",
      "(400000, 100)\n",
      "(33119, 100)\n"
     ]
    }
   ],
   "source": [
    "# 读取csv文件\n",
    "path = \"/Users/chernweiren/Dropbox/ML_project/Stroke_prediction_system_Data/\"\n",
    "train_feature_path = path + \"Prf_feature_train.csv\"\n",
    "train_label_path = path + \"Stroke_label_train.csv\"\n",
    "test_feature_path = path + \"Prf_feature_test.csv\"\n",
    "# 删去第一列\n",
    "train_features = pd.read_csv(train_feature_path).iloc[:, 1:]\n",
    "train_labels = pd.read_csv(train_label_path).iloc[:, 1:]\n",
    "test_features = pd.read_csv(test_feature_path).iloc[:, 1:]\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_features.shape)\n",
    "# 数据预处理\n",
    "train_features.fillna(0, inplace=True)\n",
    "test_features.fillna(0, inplace=True)\n",
    "'''\n",
    "redundant_cols = ['FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'CTELENM1','SEQNO', 'CTELNUM1', 'NUMHHOL3', 'NUMPHON3',\n",
    "                  'CPDEMO1B', 'X_CLLCPWT', 'X_DUALUSE', 'X_DUALCOR','X_LLCPWT2', 'X_LLCPWT', 'CELPHON1']\n",
    "for c in redundant_cols:\n",
    "    del train_features[c], test_features[c]\n",
    "'''\n",
    "\n",
    "#类型修改为object\n",
    "with open(\"/Users/chernweiren/Dropbox/ML_project/obj_cols.txt\") as f:\n",
    "    c = f.read().splitlines()\n",
    "    train_features[c] = train_features[c].astype(\"object\")\n",
    "    test_features[c] = test_features[c].astype(\"object\")\n",
    "\n",
    "#缩放\n",
    "numeric_features = train_features.dtypes[train_features.dtypes == 'float64'].index\n",
    "train_features[numeric_features] = train_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "test_features[numeric_features] = test_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "\n",
    "numeric_features = train_features.dtypes[train_features.dtypes == 'int64'].index\n",
    "train_features[numeric_features] = train_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "test_features[numeric_features] = test_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "    \n",
    "#one-hot编码\n",
    "train_features = pd.get_dummies(train_features, dummy_na=True)\n",
    "test_features = pd.get_dummies(test_features, dummy_na=True)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "train_features.fillna(0, inplace=True)\n",
    "test_features.fillna(0, inplace=True)\n",
    "train_features = pd.DataFrame(pca.fit_transform(train_features))\n",
    "test_features = pd.DataFrame(pca.fit_transform(test_features))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "#写入csv文件，方便读取\n",
    "train_features.to_csv(\"train_features.csv\")\n",
    "test_features.to_csv(\"test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取csv文件\n",
    "path = \"/Users/chernweiren/Dropbox/ML_project/Stroke_prediction_system_Data/\"\n",
    "train_feature_path = path + \"Prf_feature_train.csv\"\n",
    "train_label_path = path + \"Stroke_label_train.csv\"\n",
    "test_feature_path = path + \"Prf_feature_test.csv\"\n",
    "\n",
    "train_features = pd.read_csv('/Users/chernweiren/Dropbox/ML_project/train_features.csv').iloc[:, 1:]\n",
    "train_labels = pd.read_csv(train_label_path).iloc[:, 1:]\n",
    "\n",
    "test_features = pd.read_csv('/Users/chernweiren/Dropbox/ML_project/test_features.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = xgb.DMatrix(train_features, label=train_labels) # 组成训练集\n",
    "train_data.save_binary(\"train.buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = xgb.DMatrix(test_features) # 组成测试集\n",
    "test_data.save_binary(\"test.buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 100)\n",
      "(400000, 1)\n",
      "15461\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "train_array = np.array(train_features)\n",
    "train_labels_array = np.array(train_labels)\n",
    "print(train_labels_array[train_labels_array[:,0] == 1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_array[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance(data, labels, less_label, more_label, resample_rate):\n",
    "    assert len(labels.shape) == 1\n",
    "    assert data.shape[0] == labels.shape[0]\n",
    "    assert resample_rate > 1\n",
    "    less_data = data[labels == less_label]\n",
    "    less_num = labels[labels == less_label].sum() // less_label\n",
    "    more_num = labels.shape[0] - less_num\n",
    "    assert more_num > less_num\n",
    "    assert less_num * resample_rate < more_num\n",
    "    more_data = data[labels != less_label]\n",
    "\n",
    "    # print(less_data.shape)\n",
    "    for i in range(math.floor(resample_rate)-1):\n",
    "        if i == 0:\n",
    "            rebalanced_less_data = np.concatenate([less_data, less_data])\n",
    "        else:\n",
    "            rebalanced_less_data = np.concatenate([rebalanced_less_data, less_data])\n",
    "\n",
    "    random_sample_rate = resample_rate - math.floor(resample_rate)\n",
    "    mask = np.random.choice([True, False], size=int(less_num), p=[random_sample_rate, 1-random_sample_rate])\n",
    "    # print(mask.shape)\n",
    "    tmp_less_data = less_data[mask,:]\n",
    "    rebalanced_less_data = np.concatenate([rebalanced_less_data, tmp_less_data])\n",
    "    rebalanced_less_labels = np.zeros(rebalanced_less_data.shape[0], dtype=np.uint8) + less_label\n",
    "    print('less shape:',rebalanced_less_data.shape)\n",
    "\n",
    "    # more downsample\n",
    "    sample_prob = less_num * resample_rate / more_num\n",
    "    mask = np.random.choice([True, False], size=int(more_num), p=[sample_prob, 1-sample_prob])\n",
    "    sampled_more_data = more_data[mask,:]\n",
    "    sampled_more_labels = np.zeros(sampled_more_data.shape[0], dtype=np.uint8) + more_label\n",
    "    print('more shape:', sampled_more_data.shape)\n",
    "\n",
    "    # shuffle\n",
    "    rebalanced_data = np.concatenate([sampled_more_data, rebalanced_less_data])\n",
    "    rebalanced_labels = np.concatenate([sampled_more_labels, rebalanced_less_labels])\n",
    "    # np.random.shuffle(rebalanced_data)\n",
    "    permt = np.random.permutation(rebalanced_data.shape[0])\n",
    "    rebalanced_data = rebalanced_data[permt,:]\n",
    "    rebalanced_labels = rebalanced_labels[permt]\n",
    "    print('all shape:',rebalanced_data.shape)\n",
    "    print('all labels shape:',rebalanced_labels.shape)\n",
    "\n",
    "    return rebalanced_data, rebalanced_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less shape: (34008, 100)\n",
      "more shape: (34240, 100)\n",
      "all shape: (68248, 100)\n",
      "all labels shape: (68248,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-4.0935801 , 11.3445618 , -0.29229577, ...,  0.24679076,\n",
       "         -0.14856787, -0.09119576],\n",
       "        [ 0.49746049, -1.48272316, -1.17440961, ..., -0.11757759,\n",
       "          0.17898606,  0.11907203],\n",
       "        [-2.67586371,  2.96878576,  0.79774252, ..., -0.4643263 ,\n",
       "          0.04865677, -0.74934521],\n",
       "        ...,\n",
       "        [-1.62635703, -0.61168233, -0.05126924, ..., -0.11312305,\n",
       "         -0.73943152, -0.11895303],\n",
       "        [ 5.08842459,  0.30287563, -2.90856912, ..., -0.70196117,\n",
       "          0.32815783, -0.01156482],\n",
       "        [ 0.18190567, -1.4300922 , -1.41402791, ..., -0.13581923,\n",
       "          0.16260435, -0.5608378 ]]),\n",
       " array([2, 2, 2, ..., 2, 1, 1], dtype=uint8))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebalance(train_array, train_labels_array[:,0], 1, 2, 2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',  # 多分类的问题\n",
    "    'num_class': 2,               # 类别数，与 multisoftmax 并用\n",
    "    'gamma': 0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2\n",
    "    'max_depth': 12,               # 构建树的深度，越大越容易过拟合\n",
    "    'lambda': 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample': 0.7,              # 随机采样训练样本\n",
    "    'colsample_bytree': 0.7,       # 生成树时进行的列采样\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 0,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.007,                  # 如同学习率\n",
    "    'seed': 1000,\n",
    "    'nthread': 4,                  # cpu 线程数\n",
    "    'scale_pos_weight': 0.5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:571: FutureWarning: Pass `evals` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  format(\", \".join(args_msg)), FutureWarning\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('invalid cache item: ndarray', [array([[-3.31017363e-01, -8.52767975e-01, -5.69103453e-01, ...,\n         2.94634995e-02,  1.85555385e-01,  2.78265718e-01],\n       [ 3.25721396e+00,  1.09115486e+00,  5.19404192e+00, ...,\n        -1.08211936e+00,  3.52625276e-01, -4.09799078e-01],\n       [-2.85777364e+00, -1.67920451e+00,  8.54388836e-01, ...,\n         1.11187224e+00,  8.49114176e-01,  3.94692232e-03],\n       ...,\n       [ 6.03002067e+00, -4.12281112e-01,  2.36591070e+00, ...,\n         2.83971505e-01,  4.33783256e-01,  4.47739531e-01],\n       [ 3.94447384e+00,  6.39700893e-01,  1.41313006e-01, ...,\n        -3.46134987e-01, -8.61319113e-01, -5.23426430e-01],\n       [-1.83979786e+00, -1.04967890e+00,  7.73791415e-01, ...,\n        -8.89794891e-01,  3.72296746e-01,  4.28059860e-01]]), array([[-3.31017363e-01, -8.52767975e-01, -5.69103453e-01, ...,\n         2.94634995e-02,  1.85555385e-01,  2.78265718e-01],\n       [ 3.25721396e+00,  1.09115486e+00,  5.19404192e+00, ...,\n        -1.08211936e+00,  3.52625276e-01, -4.09799078e-01],\n       [-2.85777364e+00, -1.67920451e+00,  8.54388836e-01, ...,\n         1.11187224e+00,  8.49114176e-01,  3.94692232e-03],\n       ...,\n       [ 6.03002067e+00, -4.12281112e-01,  2.36591070e+00, ...,\n         2.83971505e-01,  4.33783256e-01,  4.47739531e-01],\n       [ 3.94447384e+00,  6.39700893e-01,  1.41313006e-01, ...,\n        -3.46134987e-01, -8.61319113e-01, -5.23426430e-01],\n       [-1.83979786e+00, -1.04967890e+00,  7.73791415e-01, ...,\n        -8.89794891e-01,  3.72296746e-01,  4.28059860e-01]])])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-ab08ccb74183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# watchlist  = [(test_data,'test'),(train_data,'train')]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwatchlist\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_train_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_train_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevals\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mstart_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, cache, model_file)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'invalid cache item: {type(d).__name__}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mdmats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('invalid cache item: ndarray', [array([[-3.31017363e-01, -8.52767975e-01, -5.69103453e-01, ...,\n         2.94634995e-02,  1.85555385e-01,  2.78265718e-01],\n       [ 3.25721396e+00,  1.09115486e+00,  5.19404192e+00, ...,\n        -1.08211936e+00,  3.52625276e-01, -4.09799078e-01],\n       [-2.85777364e+00, -1.67920451e+00,  8.54388836e-01, ...,\n         1.11187224e+00,  8.49114176e-01,  3.94692232e-03],\n       ...,\n       [ 6.03002067e+00, -4.12281112e-01,  2.36591070e+00, ...,\n         2.83971505e-01,  4.33783256e-01,  4.47739531e-01],\n       [ 3.94447384e+00,  6.39700893e-01,  1.41313006e-01, ...,\n        -3.46134987e-01, -8.61319113e-01, -5.23426430e-01],\n       [-1.83979786e+00, -1.04967890e+00,  7.73791415e-01, ...,\n        -8.89794891e-01,  3.72296746e-01,  4.28059860e-01]]), array([[-3.31017363e-01, -8.52767975e-01, -5.69103453e-01, ...,\n         2.94634995e-02,  1.85555385e-01,  2.78265718e-01],\n       [ 3.25721396e+00,  1.09115486e+00,  5.19404192e+00, ...,\n        -1.08211936e+00,  3.52625276e-01, -4.09799078e-01],\n       [-2.85777364e+00, -1.67920451e+00,  8.54388836e-01, ...,\n         1.11187224e+00,  8.49114176e-01,  3.94692232e-03],\n       ...,\n       [ 6.03002067e+00, -4.12281112e-01,  2.36591070e+00, ...,\n         2.83971505e-01,  4.33783256e-01,  4.47739531e-01],\n       [ 3.94447384e+00,  6.39700893e-01,  1.41313006e-01, ...,\n        -3.46134987e-01, -8.61319113e-01, -5.23426430e-01],\n       [-1.83979786e+00, -1.04967890e+00,  7.73791415e-01, ...,\n        -8.89794891e-01,  3.72296746e-01,  4.28059860e-01]])])"
     ]
    }
   ],
   "source": [
    "num_round = 50\n",
    "# watchlist  = [(test_data,'test'),(train_data,'train')]\n",
    "watchlist  = [(sampled_train_array,'train')]\n",
    "bst = xgb.train(params, sampled_train_array, num_round, watchlist )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Stroke\n",
       "0            2\n",
       "1            1\n",
       "2            2\n",
       "3            2\n",
       "4            2\n",
       "...        ...\n",
       "399995       2\n",
       "399996       2\n",
       "399997       2\n",
       "399998       2\n",
       "399999       2\n",
       "\n",
       "[400000 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
